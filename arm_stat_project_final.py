# -*- coding: utf-8 -*-
"""Arm_Stat_Project_Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y4w7s4qEw3X1j2ivuoNY3JtTdW9s2mNb

# 1. Data Scraping
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import numpy as np

# standard syntax of the usage of BeautifulSoup
def scrape_and_print_data(url, title):
    page = requests.get(url)
    soup = BeautifulSoup(page.content, "html.parser")
    results = soup.find(id="center")

    if results:
        print(title)

        stat_info = results.find_all("table", class_="data")
        for item in stat_info:
            for tr in item.find_all("tr"):
                row_data = [td.text.strip() for td in tr.find_all("td")]
                print("\t".join(row_data))

# Scrapping data for public school students girls with given url
def public_school_students_girls(url):
    title = "Total number of public school students, girls, from 2000 - 2022"
    scrape_and_print_data(url, title)

# same for the others
def adopted_children_girl(url):
    title = "Number of centrally registered adopted children, girls, from 2000 - 2022"
    scrape_and_print_data(url, title)

def adopted_children_boy(url):
    title = "Number of centrally registered adopted children, boys, from 2000 - 2022"
    scrape_and_print_data(url, title)

def public_school_students_boys(url):
    title = "Total number of public school students, boys, from 2000 - 2022"
    scrape_and_print_data(url, title)

# main entry of the project
if __name__ == "__main__":
    url_adopted_children_girl = "https://shorturl.at/qBSX6"
    adopted_children_girl(url_adopted_children_girl)
    print("\n")

    url_adopted_children_boy = "https://shorturl.at/aijJK"
    adopted_children_boy(url_adopted_children_boy)
    print("\n")

    url_public_school_students_boys = "https://shorturl.at/sFPS9"
    public_school_students_boys(url_public_school_students_boys)
    print("\n")

    url_public_school_students_girls = "https://shorturl.at/djEFH"
    public_school_students_girls(url_public_school_students_girls)
    print("\n")

# Scrapping data and filling it in dataframes
def scrape_and_fill_dataframe(url, title, df):
    page = requests.get(url)
    soup = BeautifulSoup(page.content, "html.parser")
    results = soup.find(id="center")

    if results:
        years = []
        absolute_values = []
        compared_percentages = []

        stat_info = results.find_all("table", class_ = "data")
        for item in stat_info:
            for tr in item.find_all("tr"):
                row_data = [td.text.strip() for td in tr.find_all("td")]

                # this part is for ignoring armenian characters, and just but the numbers into dataframe (the numbers which are needed)
                if len(row_data) < 3 or "Տարեսկզբից" in row_data:
                    continue

                # setting each parameter as row / column in dataframe
                year = row_data[0]
                absolute_value = row_data[1]
                compared_percentage = row_data[2]

                # setting "-"s in data to NaN
                absolute_value = np.nan if absolute_value == "-" else float(absolute_value)

                # working with NaNs
                compared_percentage = np.nan if not compared_percentage.replace(".", "").isdigit() else float(compared_percentage)

                # appedning rows into dataframe
                years.append(int(year))
                absolute_values.append(absolute_value)
                compared_percentages.append(compared_percentage)

        # Setting data into specific row / column
        df['Year'] = years
        df['Absolute Value'] = absolute_values
        df['Compared to Last Year (%)'] = compared_percentages

        df['Year'] = df['Year'].astype(int)
        df['Absolute Value'] = df['Absolute Value'].astype(float)
        df['Compared to Last Year (%)'] = df['Compared to Last Year (%)'].astype(float)

        df['Percentage Change'] = df['Absolute Value'].pct_change() * 100

# This is part is just for testing purposes
print("Number of centrally registered adopted girls")
adopted_children_girl_df = pd.DataFrame(columns=['Year', 'Absolute Value', 'Compared to Last Year (%)', 'Percentage Change'])
url_adopted_children_girl = "https://shorturl.at/qBSX6"
scrape_and_fill_dataframe(url_adopted_children_girl, "Number of centrally registered adopted children, girls, from 2000 - 2022", adopted_children_girl_df)
print(adopted_children_girl_df)
print("\n")

print("Number of centrally registered adopted boys")
adopted_children_boy_df = pd.DataFrame(columns=['Year', 'Absolute Value', 'Compared to Last Year (%)', 'Percentage Change'])
url_adopted_children_boy = "https://shorturl.at/qBSX6"
scrape_and_fill_dataframe(url_adopted_children_boy, "Number of centrally registered adopted children, boys, from 2000 - 2022", adopted_children_boy_df)
print(adopted_children_boy_df)
print("\n")

print("Total number of public school boys")
public_school_students_boys_df = pd.DataFrame(columns=['Year', 'Absolute Value', 'Compared to Last Year (%)', 'Percentage Change'])
url_public_school_students_boys = "https://shorturl.at/sFPS9"
scrape_and_fill_dataframe(url_public_school_students_boys, "Total number of public school students, boys, from 2000 - 2022", public_school_students_boys_df)
print(public_school_students_boys_df)
print("\n")

print("Total number of public school girls")
public_school_students_girls_df = pd.DataFrame(columns=['Year', 'Absolute Value', 'Compared to Last Year (%)', 'Percentage Change'])
url_public_school_students_girls = "https://shorturl.at/djEFH"
scrape_and_fill_dataframe(url_public_school_students_girls, "Fertility Rate per Woman, 2000 - 2022", public_school_students_girls_df)
print(public_school_students_girls_df)
print("\n")

"""# 2. Data Cleaning"""

# Function for traversing in the list

def traverse(dataframes_list, function):
    return [function(df) for df in dataframes_list]

# Handling Missing values

def handle_missing_values(df):
    # Dropping rows with missing values
    df.dropna(inplace=True)

    # Reset index after dropping rows
    df.reset_index(drop=True, inplace=True)

    # Returning None since the operation is done in-place
    return None

dataframes_list = [adopted_children_girl_df, adopted_children_boy_df, public_school_students_boys_df, public_school_students_girls_df]

traverse(dataframes_list, handle_missing_values)

# Identifying and handling outliers
def handle_outliers(df):
    Q1 = df['Absolute Value'].quantile(0.25)
    Q3 = df['Absolute Value'].quantile(0.75)
    IQR = Q3 - Q1

    # Filtering rows without outliers
    df = df[~((df['Absolute Value'] < (Q1 - 1.5 * IQR)) | (df['Absolute Value'] > (Q3 + 1.5 * IQR)))]

    # Resetting indexes after filtering outliers
    df = df.reset_index(drop = True)

    return df

traverse(dataframes_list, handle_outliers)

# Check for inconsistencies

def handle_duplicates(df):
    duplicates = df.duplicated()

    df = df.drop_duplicates()

    df = df.reset_index(drop = True)

    return df

traverse(dataframes_list, handle_duplicates)

"""# 3. Data Preprocessing"""

# Data after scraping and cleaning
# and before preprocessing

def print_dataframes(dataframes_list):
    for df in dataframes_list:
        print(df)

schoolgirls_df = pd.DataFrame(public_school_students_girls_df)
schoolboys_df = pd.DataFrame(public_school_students_boys_df)
adopted_girls_df = pd.DataFrame(adopted_children_girl_df)
adopted_boys_df = pd.DataFrame(adopted_children_boy_df)

schoolgirls_df['Gender'] = 'Girl'
schoolboys_df['Gender'] = 'Boy'
adopted_girls_df['Gender'] = 'Girl'
adopted_boys_df['Gender'] = 'Boy'


merged_df_school = pd.concat([schoolgirls_df, schoolboys_df ], ignore_index=True)
sorted_df_school = merged_df_school.sort_values(by='Absolute Value')
merged_df_adopted = pd.concat([adopted_girls_df, adopted_boys_df], ignore_index=True)
sorted_df_adopted = merged_df_adopted.sort_values(by='Absolute Value')
handle_missing_values(sorted_df_adopted)
handle_missing_values(sorted_df_school)
print("Sorted DataFrame of Schoolchildren:")
print()
print(sorted_df_school)
print()
print("Sorted DataFrame of Schoolchildren:")
print()
print(sorted_df_adopted)

sorted_df_adopted['Gender_encoded'] = sorted_df_adopted['Gender'].map({'Girl': 1, 'Boy': 0})
df_encoded_adopted = sorted_df_adopted.drop(columns=['Gender', 'Compared to Last Year (%)'])
print("Encoded DataFrame for Adopted children:")
print(df_encoded_adopted)

sorted_df_school['Gender_encoded'] = sorted_df_school['Gender'].map({'Girl': 1, 'Boy': 0})
df_encoded_school = sorted_df_school.drop(columns=['Gender', 'Compared to Last Year (%)'])
print("Encoded DataFrame for Schoolchildren:")
print(df_encoded_school)

# Adding new features

def create_new_features(df):
    df['Absolute Value'] = df['Absolute Value'] ** 2

    max_year = df['Year'].max()
    df['Year Difference'] = max_year - df['Year']

    df['Percentage Change Squared'] = df['Percentage Change'] ** 2

    return df

traverse(dataframes_list, create_new_features)

from sklearn.preprocessing import StandardScaler

def normalize_data(df):
    columns = ['Absolute Value', 'Year Difference', 'Percentage Change Squared']

    scaler = StandardScaler()

    df[columns] = scaler.fit_transform(df[columns])

    return df

traverse(dataframes_list, normalize_data)

# Using dimensionally reduction

from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

def apply_pca(df, feature_columns, n_components = 2):
    df_for_pca = df.dropna(subset = feature_columns)

    features_for_pca = df_for_pca[feature_columns]

    scaler = StandardScaler()
    features_standardized = scaler.fit_transform(features_for_pca)

    pca = PCA(n_components = n_components)
    principal_components = pca.fit_transform(features_standardized)

    pca_df = pd.DataFrame(data = principal_components, columns = [f'Principal Component {i+1}' for i in range(n_components)])

    df = pd.concat([df, pca_df], axis = 1)

    return df

traverse(dataframes_list, normalize_data)

"""# 4. Data Analysis and Visualization"""

from sklearn.impute import SimpleImputer
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import skew, kurtosis

mode_imputer = SimpleImputer(strategy='most_frequent')
median_imputer = SimpleImputer(strategy='median')
mean_imputer = SimpleImputer(strategy='mean')

mode_imputer.fit_transform(adopted_children_girl_df[['Absolute Value']])
median_imputer.fit(adopted_children_girl_df[['Absolute Value']])
mean_imputer.fit_transform(adopted_children_girl_df[['Absolute Value']])

mode = mode_imputer.statistics_
median = median_imputer.statistics_
mean = mean_imputer.statistics_

print("Mode of the data:", mode)
print("Median of the data:", median)
print("Mean of the data:", mean)

mode_imputer = SimpleImputer(strategy='most_frequent')
median_imputer = SimpleImputer(strategy='median')
mean_imputer = SimpleImputer(strategy='mean')

mode_imputer.fit_transform(adopted_children_boy_df[['Absolute Value']])
median_imputer.fit(adopted_children_boy_df[['Absolute Value']])
mean_imputer.fit_transform(adopted_children_boy_df[['Absolute Value']])

mode = mode_imputer.statistics_
median = median_imputer.statistics_
mean = mean_imputer.statistics_

print("Mode of the data:", mode)
print("Median of the data:", median)
print("Mean of the data:", mean)

def statistics_of_data(df):
    mode_imputer = SimpleImputer(strategy='most_frequent')
    median_imputer = SimpleImputer(strategy='median')
    mean_imputer = SimpleImputer(strategy='mean')
    mode_imputer.fit_transform(df)
    median_imputer.fit(df)
    mean_imputer.fit_transform(df)

    mode = (mode_imputer.statistics_).astype(int)
    median = (median_imputer.statistics_).astype(int)
    mean = (mean_imputer.statistics_).astype(int)
    std_dev = np.std(df)
    variance = np.var(df)
    skewness = skew(df)
    kurt = kurtosis(df)
    df1 = pd.DataFrame(df)

    # Pearson
    pearson_corr = df1.corr(method='pearson')

    # Spearman
    spearman_corr = df1.corr(method='spearman')

    print("Pearson Correlation:")
    print(pearson_corr)
    print("\nSpearman Correlation:")
    print(spearman_corr)

    print("Skewness:", skewness)
    print("Kurtosis:", kurt)

    print("Mode of the data:", mode)
    print("Median of the data:", median)
    print("Mean of the data:", mean)
    print("Std_dev of the data:", std_dev)
    print("Variance of the data:", variance)


# for df in dataframes_list:
#     statistics_of_data(df[['Percentage Change']])
statistics_of_data(sorted_df_adopted[['Absolute Value']])

import seaborn as sns
import matplotlib.pyplot as plt
x_column = 'Year'
y_column = 'Absolute Value'

plt.scatter(df_encoded_school[x_column], df_encoded_school[y_column])
plt.xlabel(x_column)
plt.ylabel(y_column)
plt.title('Scatter Plot of Year and Number of children at school')
plt.grid(True)
plt.show()

x_column = 'Year'
y_column = 'Absolute Value'

plt.scatter(df_encoded_adopted[x_column], df_encoded_adopted[y_column])
plt.xlabel(x_column)
plt.ylabel(y_column)
plt.title('Scatter Plot of Year and Number of children at school')
plt.grid(True)
plt.show()

df_encoded_school.set_index('Percentage Change', inplace=True)

# Create a heatmap
plt.figure(figsize=(10, 10))
sns.heatmap(df_encoded_school, annot=True, cmap='YlGnBu')
plt.title('Heatmap of Schoolchildren')
plt.xlabel('Years')
plt.ylabel('Children')
plt.show()

df_encoded_adopted.set_index('Percentage Change', inplace=True)

plt.figure(figsize=(10, 10))
sns.heatmap(df_encoded_adopted, annot=True, cmap='YlGnBu')
plt.title('Heatmap of Schoolchildren')
plt.xlabel('Years')
plt.ylabel('Children')
plt.show()

from sklearn.preprocessing import MinMaxScaler, StandardScaler
import pandas as pd

column_to_normalize = 'Year'
column_data = df_encoded_school[[column_to_normalize]]  # Selecting the column as a DataFrame for MinMaxScaler
scaler = MinMaxScaler()
normalized_column = scaler.fit_transform(column_data)
df_encoded_school[column_to_normalize] = normalized_column

print("Normalized DataFrame:")
print(df_encoded_school)

column_to_normalize = 'Year'
column_data = df_encoded_adopted[[column_to_normalize]]
scaler = MinMaxScaler()
normalized_column = scaler.fit_transform(column_data)
df_encoded_adopted[column_to_normalize] = normalized_column

print("Normalized DataFrame:")
print(df_encoded_school)

x_column = 'Year'
y_column = 'Absolute Value'

sns.scatterplot(data=df_encoded_school, x=x_column, y=y_column, hue='Gender_encoded')
plt.xlabel(x_column)
plt.ylabel(y_column)
plt.title(f'Scatter Plot of {x_column} vs {y_column}')
plt.grid(True)
plt.legend(title='Gender')
plt.show()

df_encoded_school

x_column = 'Year'
y_column = 'Absolute Value'

sns.scatterplot(data=df_encoded_adopted, x=x_column, y=y_column, hue='Gender_encoded')
plt.xlabel(x_column)
plt.ylabel(y_column)
plt.title(f'Scatter Plot of {x_column} vs {y_column}')
plt.grid(True)
plt.legend(title='Gender')
plt.show()

df_encoded_adopted.set_index('Year', inplace=True)

correlation_matrix = df_encoded_adopted.corr()

plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)
plt.title('Correlation Heatmap of Adopted children')
plt.show()

df_encoded_adopted

# import pandas as pd
# import seaborn as sns
# import matplotlib.pyplot as plt

# plt.figure(figsize=(8, 6))
# sns.barplot(x='Year', y='Absolute Value', data=df_encoded_school[:10], palette='muted')
# plt.title('Average Atendees at school')
# plt.xlabel('Year')
# plt.ylabel('Absolute Value')
# plt.show()

# plt.figure(figsize=(8, 6))
# sns.barplot(x='Year', y='Absolute Value', data=df_encoded_adopted[:10], palette='muted')
# plt.title('Average number of children adopted every year')
# plt.xlabel('Year')
# plt.ylabel('Absolute Value')
# plt.show()

# df_encoded_school.set_index('Year', inplace=True)
# new_df_encoded_school= df_encoded_school[:10]
# # Create time series plot
# plt.figure(figsize=(10, 6))
# plt.plot(new_df_encoded_school.index, new_df_encoded_school['Absolute Value'], marker='o', linestyle='-')
# plt.title('Time Series Plot')
# plt.xlabel('Date')
# plt.ylabel('Value')
# plt.grid(True)
# plt.show()

def print_histogram(df):
    # Histogram
    plt.subplot(2, 2, 1)
    sns.histplot(df, kde=True)
    plt.title("Histogram")
print_histogram(df_encoded_adopted['Absolute Value'])

def print_boxplot(df):
    plt.subplot(1, 5,2)
    sns.boxplot(data=df)
    plt.title("Boxplot")
print_boxplot(df_encoded_adopted['Absolute Value'])

def print_density_plot(df):
    plt.subplot(3, 1, 3)
    sns.kdeplot(df, fill=True)
    plt.title("Density Plot")
print_density_plot(df_encoded_adopted['Absolute Value'])

def print_violin_plot(df):
    plt.subplot(2, 2, 4)
    sns.violinplot(data=df)
    plt.title("Violin Plot")
print_violin_plot(df_encoded_school['Absolute Value'])

print_violin_plot(df_encoded_adopted['Absolute Value'])

def print_heatmap(df):
    plt.figure(figsize=(8, 6))
    sns.heatmap(df, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
    plt.title('Correlation Heatmap')
    plt.show()
print_heatmap(df_encoded_school[['Absolute Value']])

def plot_correlation(df1, df2, title):
    correlation = df1.corrwith(df2, axis=0)
    plt.figure(figsize=(8, 6))
    sns.barplot(x=correlation.index, y=correlation.values)
    plt.title(title)
    plt.xlabel('Variables')
    plt.ylabel('Correlation Coefficient')
    plt.xticks(rotation=45)
    plt.show()
plot_correlation(adopted_children_boy_df[['Absolute Value']], adopted_children_girl_df[['Absolute Value']], 'Correlation between Adopted Children (Boys) and Adopted Children (Girls)')
plot_correlation(public_school_students_boys_df[['Compared to Last Year (%)']], public_school_students_girls_df[['Compared to Last Year (%)']], 'Correlation between Public School Students (Boys) and Public School Students (Girls)')

import pandas as pd
from scipy.stats import ttest_ind
grouped_data = sorted_df_adopted.groupby(['Year', 'Gender']).size().unstack(fill_value=0)

boys_data = grouped_data['Boy']
girls_data = grouped_data['Girl']
t_statistic, p_value = ttest_ind(boys_data, girls_data)


print("T-Statistic:", t_statistic)
print("P-Value:", p_value)

alpha = 0.05  # significance level
if p_value < alpha:
    print("Reject null hypothesis: There is a significant difference in the number of adopted boys and girls each year.")
else:
    print("Fail to reject null hypothesis: There is no significant difference in the number of adopted boys and girls each year.")

import pandas as pd
from scipy.stats import ttest_ind
grouped_data = sorted_df_school.groupby(['Year', 'Gender']).size().unstack(fill_value=0)

boys_data = grouped_data['Boy']
girls_data = grouped_data['Girl']
t_statistic, p_value = ttest_ind(boys_data, girls_data)


print("T-Statistic:", t_statistic)
print("P-Value:", p_value)

alpha = 0.05  # significance level
if p_value < alpha:
    print("Reject null hypothesis: There is a significant difference in the number of adopted boys and girls each year.")
else:
    print("Fail to reject null hypothesis: There is no significant difference in the number of adopted boys and girls each year.")

sorted_df_adopted

"""# 5. ML Models Training"""

for df in dataframes_list:
    df.drop(columns=['Year Difference', 'Percentage Change Squared'], inplace = True)

dataframes_list

# dataframes_list data
# [0] adopted_children_girl
# [1] adopted_children_boy
# [2] public_school_students_boys
# [3] public_school_students_girls

from sklearn.model_selection import train_test_split

df_adopted_girl = dataframes_list[0]
df_adopted_boy = dataframes_list[1]

X_boy = df_adopted_boy[['Year', 'Absolute Value', 'Compared to Last Year (%)']]
y_boy = df_adopted_boy['Percentage Change']

X_girl = df_adopted_boy[['Year', 'Absolute Value', 'Compared to Last Year (%)']]
y_girl = df_adopted_boy['Percentage Change']

X_train_girl, X_test_girl, y_train_girl, y_test_girl = train_test_split(X_girl, y_girl, test_size=0.2, random_state=42)
X_train_boy, X_test_boy, y_train_boy, y_test_boy = train_test_split(X_boy, y_boy, test_size=0.2, random_state=42)

df_pupil_boys = dataframes_list[2]
df_pupil_girls = dataframes_list[3]

X_boys = df_pupil_boys[['Year', 'Absolute Value', 'Compared to Last Year (%)']]
y_boys = df_pupil_boys['Percentage Change']

X_girls = df_pupil_girls[['Year', 'Absolute Value', 'Compared to Last Year (%)']]
y_girls = df_pupil_girls['Percentage Change']

X_train_boys, X_test_boys, y_train_boys, y_test_boys = train_test_split(X_boys, y_boys, test_size=0.2, random_state=42)
X_train_girls, X_test_girls, y_train_girls, y_test_girls = train_test_split(X_girls, y_girls, test_size=0.2, random_state=42)

df_adopted_boy

import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression

model_adopted_boy = LinearRegression()
model_adopted_boy.fit(X_train_boy, y_train_boy)

model_adopted_girl = LinearRegression()
model_adopted_girl.fit(X_train_girl, y_train_girl)

model_pupil_boys = LinearRegression()
model_pupil_boys.fit(X_train_boys, y_train_boys)

model_pupil_girls = LinearRegression()
model_pupil_girls.fit(X_train_girls, y_train_girls)

# Make predictions
predictions_adopted_boy = model_adopted_boy.predict(X_test_boy)
predictions_adopted_girl = model_adopted_girl.predict(X_test_girl)
predictions_pupil_boys = model_pupil_boys.predict(X_test_boys)
predictions_pupil_girls = model_pupil_girls.predict(X_test_girls)


last_year_adopted_boy = df_adopted_boy['Year'].max()
next_10_years = pd.DataFrame({'Year': np.arange(last_year_adopted_boy + 1, last_year_adopted_boy + 11)})
next_10_years['Absolute Value'] = df_adopted_boy['Absolute Value'].mean()
next_10_years['Compared to Last Year (%)'] = df_adopted_boy['Compared to Last Year (%)'].mean()
next_10_years['Predicted Percentage Change'] = model_adopted_boy.predict(next_10_years[['Year', 'Absolute Value', 'Compared to Last Year (%)']])

print(next_10_years[['Year', 'Predicted Percentage Change']])

# Make predictions for the next 10 years for adopted girls
last_year_adopted_girl = df_adopted_girl['Year'].max()
next_10_years_adopted_girl = pd.DataFrame({'Year': np.arange(last_year_adopted_girl + 1, last_year_adopted_girl + 11)})
next_10_years_adopted_girl['Absolute Value'] = df_adopted_girl['Absolute Value'].mean()
next_10_years_adopted_girl['Compared to Last Year (%)'] = df_adopted_girl['Compared to Last Year (%)'].mean()
next_10_years_adopted_girl['Predicted Percentage Change'] = model_adopted_girl.predict(next_10_years_adopted_girl[['Year', 'Absolute Value', 'Compared to Last Year (%)']])

print(next_10_years_adopted_girl[['Year', 'Predicted Percentage Change']])

# Make predictions for the next 10 years for pupil boys
last_year_pupil_boys = df_pupil_boys['Year'].max()
next_10_years_pupil_boys = pd.DataFrame({'Year': np.arange(last_year_pupil_boys + 1, last_year_pupil_boys + 11)})
next_10_years_pupil_boys['Absolute Value'] = df_pupil_boys['Absolute Value'].mean()
next_10_years_pupil_boys['Compared to Last Year (%)'] = df_pupil_boys['Compared to Last Year (%)'].mean()
next_10_years_pupil_boys['Predicted Percentage Change'] = model_pupil_boys.predict(next_10_years_pupil_boys[['Year', 'Absolute Value', 'Compared to Last Year (%)']])

print(next_10_years_pupil_boys[['Year', 'Predicted Percentage Change']])

# Make predictions for the next 10 years for pupil girls
last_year_pupil_girls = df_pupil_girls['Year'].max()
next_10_years_pupil_girls = pd.DataFrame({'Year': np.arange(last_year_pupil_girls + 1, last_year_pupil_girls + 11)})
next_10_years_pupil_girls['Absolute Value'] = df_pupil_girls['Absolute Value'].mean()
next_10_years_pupil_girls['Compared to Last Year (%)'] = df_pupil_girls['Compared to Last Year (%)'].mean()
next_10_years_pupil_girls['Predicted Percentage Change'] = model_pupil_girls.predict(next_10_years_pupil_girls[['Year', 'Absolute Value', 'Compared to Last Year (%)']])

print(next_10_years_pupil_girls[['Year', 'Predicted Percentage Change']])

# Optimizing the model parameters for better performance
from sklearn.model_selection import GridSearchCV

param_grid = {
    'fit_intercept' : [True, False],
}

# Optimizing the model parameters for df_adopted_boy
grid_search_adopted_boy = GridSearchCV(LinearRegression(), param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
grid_search_adopted_boy.fit(X_train_boy, y_train_boy)
best_params_adopted_boy = grid_search_adopted_boy.best_params_
best_model_adopted_boy = LinearRegression(**best_params_adopted_boy)
best_model_adopted_boy.fit(X_train_boy, y_train_boy)
predictions_adopted_boy = best_model_adopted_boy.predict(X_test_boy)

# Optimizing the model parameters for df_adopted_girl
grid_search_adopted_girl = GridSearchCV(LinearRegression(), param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
grid_search_adopted_girl.fit(X_train_girl, y_train_girl)
best_params_adopted_girl = grid_search_adopted_girl.best_params_
best_model_adopted_girl = LinearRegression(**best_params_adopted_girl)
best_model_adopted_girl.fit(X_train_girl, y_train_girl)
predictions_adopted_girl = best_model_adopted_girl.predict(X_test_girl)

# Optimizing the model parameters for df_pupil_boys
grid_search_pupil_boys = GridSearchCV(LinearRegression(), param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
grid_search_pupil_boys.fit(X_train_boys, y_train_boys)
best_params_pupil_boys = grid_search_pupil_boys.best_params_
best_model_pupil_boys = LinearRegression(**best_params_pupil_boys)
best_model_pupil_boys.fit(X_train_boys, y_train_boys)
predictions_pupil_boys = best_model_pupil_boys.predict(X_test_boys)

# Optimizing the model parameters for df_pupil_girls
grid_search_pupil_girls = GridSearchCV(LinearRegression(), param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
grid_search_pupil_girls.fit(X_train_girls, y_train_girls)
best_params_pupil_girls = grid_search_pupil_girls.best_params_
best_model_pupil_girls = LinearRegression(**best_params_pupil_girls)
best_model_pupil_girls.fit(X_train_girls, y_train_girls)
predictions_pupil_girls = best_model_pupil_girls.predict(X_test_girls)

# Implementing cross-validation to ensure the model's generalizability
from sklearn.model_selection import cross_val_score

# For df_adopted_boy
model_adopted_boy = LinearRegression()
cv_scores_adopted_boy = cross_val_score(model_adopted_boy, X_train_boy, y_train_boy, cv=5)

print(cv_scores_adopted_boy)

# For df_adopted_girl
model_adopted_girl = LinearRegression()
cv_scores_adopted_girl = cross_val_score(model_adopted_girl, X_train_girl, y_train_girl, cv=5)

print(cv_scores_adopted_girl)

# For df_pupil_boys
model_pupil_boys = LinearRegression()
cv_scores_pupil_boys = cross_val_score(model_pupil_boys, X_train_boys, y_train_boys, cv=5)

print(cv_scores_pupil_boys)

# For df_pupil_girls
model_pupil_girls = LinearRegression()
cv_scores_pupil_girls = cross_val_score(model_pupil_girls, X_train_girls, y_train_girls, cv=5)

print(cv_scores_pupil_girls)

# Evaluating the models using the testing dataset
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# df_adopted_boy
predictions_adopted_boy = best_model_adopted_boy.predict(X_test_boy)
mae_adopted_boy = mean_absolute_error(y_test_boy, predictions_adopted_boy)
mse_adopted_boy = mean_squared_error(y_test_boy, predictions_adopted_boy)
rmse_adopted_boy = np.sqrt(mse_adopted_boy)

print("Evaluation results for df_adopted_boy:")
print("Mean Absolute Error:", mae_adopted_boy)
print("Mean Squared Error:", mse_adopted_boy)
print("Root Mean Squared Error:", rmse_adopted_boy)

# df_adopted_girl
predictions_adopted_girl = best_model_adopted_girl.predict(X_test_girl)
mae_adopted_girl = mean_absolute_error(y_test_girl, predictions_adopted_girl)
mse_adopted_girl = mean_squared_error(y_test_girl, predictions_adopted_girl)
rmse_adopted_girl = np.sqrt(mse_adopted_girl)

print("Evaluation results for df_adopted_girl:")
print("Mean Absolute Error:", mae_adopted_girl)
print("Mean Squared Error:", mse_adopted_girl)
print("Root Mean Squared Error:", rmse_adopted_girl)

# df_pupil_boys
predictions_pupil_boys = best_model_pupil_boys.predict(X_test_boys)
mae_pupil_boys = mean_absolute_error(y_test_boys, predictions_pupil_boys)
mse_pupil_boys = mean_squared_error(y_test_boys, predictions_pupil_boys)
rmse_pupil_boys = np.sqrt(mse_pupil_boys)

print("Evaluation results for df_pupil_boys:")
print("Mean Absolute Error:", mae_pupil_boys)
print("Mean Squared Error:", mse_pupil_boys)
print("Root Mean Squared Error:", rmse_pupil_boys)

# df_pupil_girls
predictions_pupil_girls = best_model_pupil_girls.predict(X_test_girls)
mae_pupil_girls = mean_absolute_error(y_test_girls, predictions_pupil_girls)
mse_pupil_girls = mean_squared_error(y_test_girls, predictions_pupil_girls)
rmse_pupil_girls = np.sqrt(mse_pupil_girls)

print("Evaluation results for df_pupil_girls:")
print("Mean Absolute Error:", mae_pupil_girls)
print("Mean Squared Error:", mse_pupil_girls)
print("Root Mean Squared Error:", rmse_pupil_girls)

"""# Best ML model selection"""

from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

polynomial_features = PolynomialFeatures(degree=2, include_bias=False)

param_grid = {
    'randomforestregressor__n_estimators': [50, 100, 200],
    'randomforestregressor__max_depth': [None, 10, 20],
    'randomforestregressor__min_samples_split': [2, 5, 10],
}

pipeline = Pipeline([
    ('polynomial_features', polynomial_features),
    ('scaler', StandardScaler()),
    ('randomforestregressor', RandomForestRegressor())
])

grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
grid_search.fit(X_train_boy, y_train_boy)

best_model = grid_search.best_estimator_

predictions = best_model.predict(X_test_boy)
mse = mean_squared_error(y_test_boy, predictions)
rmse = np.sqrt(mse)

print("Best Model:", best_model)
print("Root Mean Squared Error:", rmse)

from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error

interaction_features = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)

param_grid = {
    'gradientboostingregressor__n_estimators': [50, 100, 200],
    'gradientboostingregressor__learning_rate': [0.01, 0.1, 0.5],
    'gradientboostingregressor__max_depth': [3, 5, 7],
}

pipeline = Pipeline([
    ('interaction_features', interaction_features),
    ('scaler', StandardScaler()),
    ('gradientboostingregressor', GradientBoostingRegressor())
])

grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
grid_search.fit(X_train_boy, y_train_boy)

best_model = grid_search.best_estimator_

predictions = best_model.predict(X_test_boy)
mse = mean_squared_error(y_test_boy, predictions)
rmse = np.sqrt(mse)

print("Best Model:", best_model)
print("Root Mean Squared Error:", rmse)

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
def evaluate_model(model, X_test, y_test):
    predictions = model.predict(X_test)
    mae = mean_absolute_error(y_test, predictions)
    mse = mean_squared_error(y_test, predictions)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, predictions)

    print("Mean Absolute Error:", mae)
    print("Mean Squared Error:", mse)
    print("Root Mean Squared Error:", rmse)
    print("R-squared Score:", r2)

print("Performance of Best Model for Adopted Boys:")
evaluate_model(best_model_adopted_boy, X_test_boy, y_test_boy)

print("\nPerformance of Best Model for Adopted Girls:")
evaluate_model(best_model_adopted_girl, X_test_girl, y_test_girl)

print("\nPerformance of Best Model for Pupil Boys:")
evaluate_model(best_model_pupil_boys, X_test_boys, y_test_boys)

print("\nPerformance of Best Model for Pupil Girls:")
evaluate_model(best_model_pupil_girls, X_test_girls, y_test_girls)

from sklearn.model_selection import cross_validate
from sklearn.metrics import mean_squared_error, mean_absolute_error, make_scorer

scoring = {
    'neg_mean_squared_error': make_scorer(mean_squared_error, greater_is_better=False),
    'neg_mean_absolute_error': make_scorer(mean_absolute_error, greater_is_better=False)
}
cv_results_boy = cross_validate(best_model_adopted_boy, X_boy, y_boy, cv=5, scoring=scoring)
cv_results_girl = cross_validate(best_model_adopted_girl, X_girl, y_girl, cv=5, scoring=scoring)
cv_results_pupil_boys = cross_validate(best_model_pupil_boys, X_boys, y_boys, cv=5, scoring=scoring)
cv_results_pupil_girls = cross_validate(best_model_pupil_girls, X_girls, y_girls, cv=5, scoring=scoring)

print("Metrics for Adopted Boys:")
print("Mean Squared Error:", -cv_results_boy['test_neg_mean_squared_error'].mean())
print("Mean Absolute Error:", -cv_results_boy['test_neg_mean_absolute_error'].mean())

print("\nMetrics for Adopted Girls:")
print("Mean Squared Error:", -cv_results_girl['test_neg_mean_squared_error'].mean())
print("Mean Absolute Error:", -cv_results_girl['test_neg_mean_absolute_error'].mean())

print("\nMetrics for Pupil Boys:")
print("Mean Squared Error:", -cv_results_pupil_boys['test_neg_mean_squared_error'].mean())
print("Mean Absolute Error:", -cv_results_pupil_boys['test_neg_mean_absolute_error'].mean())

print("\nMetrics for Pupil Girls:")
print("Mean Squared Error:", -cv_results_pupil_girls['test_neg_mean_squared_error'].mean())
print("Mean Absolute Error:", -cv_results_pupil_girls['test_neg_mean_absolute_error'].mean())

# Evaluate a model and return regression metrics
def evaluate_model_regression(model, X_test, y_test):
    predictions = model.predict(X_test)
    mae = mean_absolute_error(y_test, predictions)
    mse = mean_squared_error(y_test, predictions)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, predictions)

    return {
        'MAE': mae,
        'MSE': mse,
        'RMSE': rmse,
        'R2': r2
    }

# Different models' evaluation
evaluations = {}
evaluations['adopted_boy'] = evaluate_model_regression(best_model_adopted_boy, X_test_boy, y_test_boy)
evaluations['adopted_girl'] = evaluate_model_regression(best_model_adopted_girl, X_test_girl, y_test_girl)
evaluations['pupil_boys'] = evaluate_model_regression(best_model_pupil_boys, X_test_boys, y_test_boys)
evaluations['pupil_girls'] = evaluate_model_regression(best_model_pupil_girls, X_test_girls, y_test_girls)


print("Evaluation metrics for each model:")
for model_name, metrics in evaluations.items():
    print(f"\n{model_name.capitalize()}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value}")

# Best model based on these 4 options
chosen_metric = 'MAE'  # 'MAE', 'MSE', 'RMSE', 'R2'
best_model = min(evaluations, key=lambda x: evaluations[x][chosen_metric])
print(f"\nThe best model based on {chosen_metric} is: {best_model.capitalize()}")

from sklearn.cluster import KMeans
import numpy as np

features = np.array([list(metrics.values()) for metrics in evaluations.values()])
n_clusters = 2

kmeans = KMeans(n_clusters=n_clusters)
kmeans.fit(features)
cluster_labels = kmeans.labels_
print("Cluster Assignments:")
for model_name, label in zip(evaluations.keys(), cluster_labels):
    print(f"{model_name.capitalize()}: Cluster {label + 1}")

import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))

for cluster_label in range(n_clusters):
    cluster_data = features[cluster_labels == cluster_label]
    plt.scatter(cluster_data[:, 0], cluster_data[:, 1], label=f'Cluster {cluster_label + 1}')

plt.xlabel('MAE')
plt.ylabel('MSE')
plt.title('Clusters of Regression Models based on Evaluation Metrics')
plt.legend()
plt.grid(True)
plt.show()